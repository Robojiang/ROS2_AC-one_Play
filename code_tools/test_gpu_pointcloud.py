#!/usr/bin/env python3
"""
æµ‹è¯•GPUåŠ é€Ÿç‚¹äº‘ç”Ÿæˆå™¨çš„æ€§èƒ½
"""

import os
import sys
import time
import numpy as np
import h5py
import json
import cv2
import torch
from scipy.spatial.transform import Rotation as R

# æ·»åŠ è·¯å¾„
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(BASE_DIR, "code_tools"))

# å¯¼å…¥GPUç”Ÿæˆå™¨ (ä»convert_hdf5_to_zarr.py)
from convert_hdf5_to_zarr import (
    GPUPointCloudGenerator,
    load_intrinsics,
    load_calibration_matrix,
    eef_to_matrix,
    decode_jpeg
)

# é…ç½®
CALIBRATION_DIR = os.path.join(BASE_DIR, "calibration_results")
DATASETS_DIR = os.path.join(BASE_DIR, "datasets")
TEST_EPISODE = os.path.join(DATASETS_DIR, "episode_0.hdf5")
NUM_FRAMES_TEST = 50  # æµ‹è¯•50å¸§

def load_test_data():
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    print(f"åŠ è½½æµ‹è¯•æ•°æ®: {TEST_EPISODE}")
    
    with h5py.File(TEST_EPISODE, 'r') as f:
        eef_data = f['observations/eef'][()][:NUM_FRAMES_TEST]
        
        # è§£ç å›¾åƒ
        head_imgs = [decode_jpeg(d) for d in f['observations/images/head'][()][:NUM_FRAMES_TEST]]
        left_imgs = [decode_jpeg(d) for d in f['observations/images/left_wrist'][()][:NUM_FRAMES_TEST]]
        right_imgs = [decode_jpeg(d) for d in f['observations/images/right_wrist'][()][:NUM_FRAMES_TEST]]
        
        # æ·±åº¦
        head_depths = f['observations/images_depth/head'][()][:NUM_FRAMES_TEST]
        left_depths = f['observations/images_depth/left_wrist'][()][:NUM_FRAMES_TEST]
        right_depths = f['observations/images_depth/right_wrist'][()][:NUM_FRAMES_TEST]
        
    return {
        'eef': eef_data,
        'head_images': np.array(head_imgs),
        'left_images': np.array(left_imgs),
        'right_images': np.array(right_imgs),
        'head_depths': head_depths,
        'left_depths': left_depths,
        'right_depths': right_depths,
    }

def load_calibration():
    """åŠ è½½æ ‡å®šæ•°æ®"""
    T_LE_LC = load_calibration_matrix("left_eye_in_hand.npy")
    T_RE_RC = load_calibration_matrix("right_eye_in_hand.npy")
    T_LB_H = load_calibration_matrix("head_base_to_left_refined_icp.txt")
    T_RB_H = load_calibration_matrix("head_base_to_right_refined_icp.txt")
    
    if np.array_equal(T_LB_H, np.eye(4)):
        T_LB_H = load_calibration_matrix("head_base_to_left.npy")
    if np.array_equal(T_RB_H, np.eye(4)):
        T_RB_H = load_calibration_matrix("head_base_to_right.npy")
    
    T_H_LB = T_LB_H
    T_H_RB = np.linalg.inv(T_RB_H)
    
    intrinsics = {
        'head': load_intrinsics('head'),
        'left': load_intrinsics('left'),
        'right': load_intrinsics('right')
    }
    
    return T_H_LB, T_H_RB, T_LE_LC, T_RE_RC, T_LB_H, intrinsics

def benchmark_gpu():
    """æµ‹è¯•GPUç‰ˆæœ¬æ€§èƒ½"""
    print("\n" + "="*80)
    print("âš¡ GPUåŠ é€Ÿç‚¹äº‘ç”Ÿæˆå™¨æ€§èƒ½æµ‹è¯•")
    print("="*80)
    
    # åŠ è½½æ•°æ®
    data = load_test_data()
    T_H_LB, T_H_RB, T_LE_LC, T_RE_RC, T_LB_H, intrinsics = load_calibration()
    
    # åˆå§‹åŒ–GPUç”Ÿæˆå™¨
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\nè®¾å¤‡: {device}")
    if device == 'cuda':
        print(f"GPU: {torch.cuda.get_device_name(0)}")
    
    generator = GPUPointCloudGenerator(
        intrinsics=intrinsics,
        downsample_size=(160, 120),
        device=device
    )
    
    # é¢„çƒ­
    print("\né¢„çƒ­ (3å¸§)...")
    for i in range(3):
        left_eef = data['eef'][i, :7]
        right_eef = data['eef'][i, 7:14]
        
        generator.generate_frame(
            head_depth=data['head_depths'][i],
            head_color=data['head_images'][i],
            left_depth=data['left_depths'][i],
            left_color=data['left_images'][i],
            right_depth=data['right_depths'][i],
            right_color=data['right_images'][i],
            left_eef=left_eef,
            right_eef=right_eef,
            T_H_LB=T_H_LB,
            T_H_RB=T_H_RB,
            T_LE_LC=T_LE_LC,
            T_RE_RC=T_RE_RC,
            T_LB_H=T_LB_H,
            max_depth_head=1.0,
            max_depth_hand=0.6,
            use_workspace_crop=True,
            workspace_x_range=[-0.4, 0.5],
            workspace_y_range=[-0.5, 3.0],
            workspace_z_range=[-0.2, 1.0]
        )
    
    # æ­£å¼æµ‹è¯•
    print(f"\nå¼€å§‹æµ‹è¯• ({NUM_FRAMES_TEST} å¸§)...")
    start_time = time.time()
    
    for i in range(NUM_FRAMES_TEST):
        left_eef = data['eef'][i, :7]
        right_eef = data['eef'][i, 7:14]
        
        pc = generator.generate_frame(
            head_depth=data['head_depths'][i],
            head_color=data['head_images'][i],
            left_depth=data['left_depths'][i],
            left_color=data['left_images'][i],
            right_depth=data['right_depths'][i],
            right_color=data['right_images'][i],
            left_eef=left_eef,
            right_eef=right_eef,
            T_H_LB=T_H_LB,
            T_H_RB=T_H_RB,
            T_LE_LC=T_LE_LC,
            T_RE_RC=T_RE_RC,
            T_LB_H=T_LB_H,
            max_depth_head=1.0,
            max_depth_hand=0.6,
            use_workspace_crop=True,
            workspace_x_range=[-0.4, 0.5],
            workspace_y_range=[-0.5, 3.0],
            workspace_z_range=[-0.2, 1.0]
        )
        
        if i == 0:
            print(f"   é¦–å¸§ç‚¹äº‘å½¢çŠ¶: {pc.shape}")
    
    elapsed = time.time() - start_time
    fps = NUM_FRAMES_TEST / elapsed
    
    print("\n" + "="*80)
    print("ğŸ“Š æ€§èƒ½æŠ¥å‘Š")
    print("="*80)
    print(f"æ€»å¸§æ•°: {NUM_FRAMES_TEST}")
    print(f"æ€»è€—æ—¶: {elapsed:.3f} ç§’")
    print(f"å¹³å‡é€Ÿåº¦: {fps:.2f} FPS")
    print(f"å•å¸§è€—æ—¶: {elapsed/NUM_FRAMES_TEST*1000:.2f} ms")
    print(f"å®æ—¶æ§åˆ¶è¦æ±‚: {'âœ… æ»¡è¶³ (>10Hz)' if fps > 10 else 'âŒ ä¸æ»¡è¶³ (<10Hz)'}")
    print("="*80)

if __name__ == '__main__':
    benchmark_gpu()
