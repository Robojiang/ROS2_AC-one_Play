#!/usr/bin/env python3
# -*- coding:utf-8 -*-

import os
import h5py
import cv2
import json
import numpy as np
from scipy.spatial.transform import Rotation as R
import open3d as o3d

# ================= é…ç½® =================
HDF5_PATH = "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/arx_data/ROS2_AC-one_Play/datasets/episode_4.hdf5"
CALIBRATION_DIR = "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/arx_data/ROS2_AC-one_Play/calibration_results"
INTRINSICS_FILE = "/media/tao/E8F6F2ECF6F2BA40/bimanial_manipulation/RoboTwin/arx_data/ROS2_AC-one_Play/calibration_results/intrinsics.json"

FRAME_INDEX = 0  # è¯»å–ç¬¬ä¸€å¸§
MAX_DEPTH_Head = 1 # æœ€å¤§æ·±åº¦é™åˆ¶ (ç±³)
MAX_DEPTH_Hand = 0.6  # æœ€å¤§æ·±åº¦é™åˆ¶ (ç±³)
FPS_SAMPLE_POINTS = 2048  # FPSé‡‡æ ·ç‚¹æ•°

# å·¥ä½œç©ºé—´è£å‰ª (ç›¸å¯¹äºå·¦è‡‚åŸºåº§åæ ‡ç³»)
USE_WORKSPACE_CROP = True  # æ˜¯å¦å¯ç”¨å·¥ä½œç©ºé—´è£å‰ª
WORKSPACE_X_RANGE = [-0.4, 0.5]  # xè½´èŒƒå›´ (ç±³)
WORKSPACE_Y_RANGE = [-0.5, 3]  # yè½´èŒƒå›´ (ç±³)
WORKSPACE_Z_RANGE = [-0.2, 1]  # zè½´èŒƒå›´ (ç±³)

# è¾“å‡ºåæ ‡ç³»é€‰æ‹©
OUTPUT_FRAME = 'left_base'  # 'head' æˆ– 'left_base' - æœ€ç»ˆç‚¹äº‘ç›¸å¯¹çš„åæ ‡ç³»

# ================= è¾…åŠ©å‡½æ•° =================

def load_intrinsics(camera_name):
    """åŠ è½½ç›¸æœºå†…å‚"""
    with open(INTRINSICS_FILE, 'r') as f:
        all_data = json.load(f)
    d = all_data[camera_name]
    fx, fy = d['fx'], d['fy']
    cx, cy = d['cx'], d['cy']
    return fx, fy, cx, cy

def load_calibration_matrix(filename):
    """åŠ è½½æ ‡å®šçŸ©é˜µ"""
    path = os.path.join(CALIBRATION_DIR, filename)
    if os.path.exists(path):
        if path.endswith('.npy'):
            return np.load(path)
        elif path.endswith('.txt'):
            return np.loadtxt(path)
    print(f"âŒ ç¼ºå°‘æ ‡å®šæ–‡ä»¶: {filename}")
    return np.eye(4)

def eef_to_matrix(eef_pose):
    """
    å°† end-effector pose è½¬æ¢ä¸º 4x4 å˜æ¢çŸ©é˜µ
    eef_pose: [x, y, z, rx, ry, rz, gripper] é•¿åº¦ä¸º7
    """
    if eef_pose is None or len(eef_pose) < 6:
        return np.eye(4)
    
    t = np.array(eef_pose[:3])
    r = R.from_euler('xyz', eef_pose[3:6]).as_matrix()
    
    T = np.eye(4)
    T[:3, :3] = r
    T[:3, 3] = t
    return T

def depth_to_point_cloud(depth_img, color_img, fx, fy, cx, cy, max_depth=None):
    """
    å°†æ·±åº¦å›¾å’Œå½©è‰²å›¾è½¬æ¢ä¸ºç‚¹äº‘
    
    è¾“å…¥:
      depth_img: (H, W) uint16, å•ä½ mm
      color_img: (H, W, 3) BGR uint8
      max_depth: æœ€å¤§æ·±åº¦é™åˆ¶ (ç±³), è¶…è¿‡æ­¤æ·±åº¦çš„ç‚¹å°†è¢«è¿‡æ»¤
    è¾“å‡º:
      points: (N, 6) [x, y, z, r, g, b] in meters
    """
    h, w = depth_img.shape
    u, v = np.meshgrid(np.arange(w), np.arange(h))
    
    # è¿‡æ»¤æ— æ•ˆæ·±åº¦
    valid = depth_img > 0
    
    # è¿‡æ»¤è·ç¦»è¿‡è¿œçš„ç‚¹
    if max_depth is not None:
        valid = valid & (depth_img < max_depth * 1000)  # è½¬æ¢ä¸ºmm
    
    z = depth_img[valid].astype(np.float32) / 1000.0  # mm -> m
    u = u[valid]
    v = v[valid]
    
    # åæŠ•å½±
    x = (u - cx) * z / fx
    y = (v - cy) * z / fy
    
    # é¢œè‰² (BGR -> RGB, 0-1)
    b = color_img[valid, 0].astype(np.float32) / 255.0
    g = color_img[valid, 1].astype(np.float32) / 255.0
    r = color_img[valid, 2].astype(np.float32) / 255.0
    
    xyz = np.stack((x, y, z), axis=1)
    rgb = np.stack((r, g, b), axis=1)
    
    return np.hstack((xyz, rgb))

def transform_point_cloud(cloud, T):
    """å˜æ¢ç‚¹äº‘, cloud: (N, 6), T: (4, 4)"""
    xyz = cloud[:, :3]
    rgb = cloud[:, 3:]
    
    ones = np.ones((xyz.shape[0], 1))
    xyz_homo = np.hstack((xyz, ones))
    
    xyz_trans = (T @ xyz_homo.T).T
    xyz_new = xyz_trans[:, :3]
    
    return np.hstack((xyz_new, rgb))

def numpy_to_o3d(cloud_np):
    """è½¬æ¢ (N, 6) numpy æ•°ç»„åˆ° open3d.geometry.PointCloud"""
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(cloud_np[:, :3])
    pcd.colors = o3d.utility.Vector3dVector(cloud_np[:, 3:])
    return pcd

def crop_point_cloud(cloud_np, x_range, y_range, z_range):
    """
    è£å‰ªç‚¹äº‘åˆ°æŒ‡å®šçš„xyzèŒƒå›´
    cloud_np: (N, 6) [x, y, z, r, g, b]
    x_range, y_range, z_range: [min, max]
    """
    xyz = cloud_np[:, :3]
    
    mask = (
        (xyz[:, 0] >= x_range[0]) & (xyz[:, 0] <= x_range[1]) &
        (xyz[:, 1] >= y_range[0]) & (xyz[:, 1] <= y_range[1]) &
        (xyz[:, 2] >= z_range[0]) & (xyz[:, 2] <= z_range[1])
    )
    
    return cloud_np[mask]

def visualize_merged(clouds_list, title="Point Cloud", coordinate_frames=[]):
    """
    å¯è§†åŒ–åˆå¹¶çš„ç‚¹äº‘
    clouds_list: list of numpy arrays (N, 6) or o3d.PointCloud
    coordinate_frames: list of (T_matrix, label, size)
    """
    print(f"ğŸ‘€ æ˜¾ç¤º: {title}")
    geometries = []
    
    # World Origin
    axes_world = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.2, origin=[0, 0, 0])
    geometries.append(axes_world)
    
    # Point Clouds
    for cloud_obj in clouds_list:
        if isinstance(cloud_obj, np.ndarray):
            if len(cloud_obj) > 0:
                pcd = numpy_to_o3d(cloud_obj)
                geometries.append(pcd)
        else:
            geometries.append(cloud_obj)
    
    # Coordinate Frames
    for item in coordinate_frames:
        if len(item) == 2:
            T, label = item
            size = 0.15
        else:
            T, label, size = item
            
        if T is not None:
            frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)
            frame.transform(T)
            geometries.append(frame)
            print(f"  -> Frame: {label} at {T[:3, 3]}")
    
    o3d.visualization.draw_geometries(geometries, window_name=title, width=1280, height=720)

def decode_jpeg(data):
    """è§£ç JPEGæ•°æ®"""
    return cv2.imdecode(np.frombuffer(data, dtype=np.uint8), cv2.IMREAD_COLOR)

# ================= ä¸»ç¨‹åº =================

def main():
    print("="*80)
    print("ä» HDF5 æ–‡ä»¶ç”Ÿæˆæ‹¼æ¥ç‚¹äº‘")
    print("="*80)
    
    # 1. åŠ è½½æ ‡å®šç»“æœ (ä½¿ç”¨ä¿®æ­£åçš„ ICP ç»“æœ)
    print("\nğŸ“ åŠ è½½æ ‡å®šæ–‡ä»¶...")
    
    # Eye-in-Hand: T_End_Cam
    T_LE_LC = load_calibration_matrix("left_eye_in_hand.npy")
    T_RE_RC = load_calibration_matrix("right_eye_in_hand.npy")
    
    # Eye-to-Hand: T_Base_HeadCam (ä½¿ç”¨ ICP ä¿®æ­£ç‰ˆæœ¬)
    T_LB_H = load_calibration_matrix("head_base_to_left_refined_icp.txt")
    T_RB_H = load_calibration_matrix("head_base_to_right_refined_icp.txt")
    
    # å¦‚æœæ²¡æœ‰ä¿®æ­£ç‰ˆæœ¬,å°è¯•åŠ è½½åŸå§‹ç‰ˆæœ¬
    if np.array_equal(T_LB_H, np.eye(4)):
        print("  âš ï¸ æœªæ‰¾åˆ° left ICP ä¿®æ­£ç‰ˆæœ¬,ä½¿ç”¨åŸå§‹æ ‡å®š")
        T_LB_H = load_calibration_matrix("head_base_to_left.npy")
    
    if np.array_equal(T_RB_H, np.eye(4)):
        print("  âš ï¸ æœªæ‰¾åˆ° right ICP ä¿®æ­£ç‰ˆæœ¬,ä½¿ç”¨åŸå§‹æ ‡å®š")
        T_RB_H = load_calibration_matrix("head_base_to_right.npy")
    
    # è½¬æ¢ä¸º T_HeadCam_Base
    T_H_LB = np.linalg.inv(T_LB_H)
    T_H_RB = np.linalg.inv(T_RB_H)
    
    print("âœ… æ ‡å®šæ–‡ä»¶åŠ è½½å®Œæˆ")
    
    # 2. åŠ è½½å†…å‚
    print("\nğŸ“ åŠ è½½ç›¸æœºå†…å‚...")
    intrinsics = {
        'head': load_intrinsics('head'),
        'left': load_intrinsics('left'),
        'right': load_intrinsics('right')
    }
    print("âœ… å†…å‚åŠ è½½å®Œæˆ")
    
    # 3. è¯»å– HDF5 æ•°æ®
    print(f"\nğŸ“ è¯»å– HDF5 æ–‡ä»¶: {os.path.basename(HDF5_PATH)}")
    print(f"   å¸§ç´¢å¼•: {FRAME_INDEX}")
    
    with h5py.File(HDF5_PATH, 'r') as f:
        # è¯»å–æœºå™¨äººçŠ¶æ€
        eef_data = f['observations/eef'][FRAME_INDEX]  # shape: (14,) = left(7) + right(7)
        
        # åˆ†ç¦»å·¦å³è‡‚
        left_eef = eef_data[:7]  # [x, y, z, rx, ry, rz, gripper]
        right_eef = eef_data[7:14]
        
        print(f"\nğŸ¤– æœºå™¨äººçŠ¶æ€:")
        print(f"   Left EEF:  {left_eef[:3]} (ä½ç½®)")
        print(f"   Right EEF: {right_eef[:3]} (ä½ç½®)")
        
        # è½¬æ¢ä¸ºå˜æ¢çŸ©é˜µ
        T_LB_LE = eef_to_matrix(left_eef)  # Left Base -> Left End
        T_RB_RE = eef_to_matrix(right_eef)  # Right Base -> Right End
        
        # è¯»å–å›¾åƒæ•°æ®
        head_color_data = f['observations/images/head'][FRAME_INDEX]
        left_color_data = f['observations/images/left_wrist'][FRAME_INDEX]
        right_color_data = f['observations/images/right_wrist'][FRAME_INDEX]
        
        head_depth = f['observations/images_depth/head'][FRAME_INDEX]
        left_depth = f['observations/images_depth/left_wrist'][FRAME_INDEX]
        right_depth = f['observations/images_depth/right_wrist'][FRAME_INDEX]
        
        # è§£ç  JPEG å›¾åƒ
        head_color = decode_jpeg(head_color_data)
        left_color = decode_jpeg(left_color_data)
        right_color = decode_jpeg(right_color_data)
    
    print(f"âœ… æ•°æ®è¯»å–å®Œæˆ")
    print(f"   å›¾åƒå°ºå¯¸: {head_color.shape}")
    print(f"   æ·±åº¦å°ºå¯¸: {head_depth.shape}")
    
    # 4. ç”Ÿæˆç‚¹äº‘
    print(f"\nğŸŒ ç”Ÿæˆç‚¹äº‘ (æœ€å¤§æ·±åº¦: Head={MAX_DEPTH_Head}m, Hand={MAX_DEPTH_Hand}m)...")
    
    clouds_local = {}
    clouds_global = []
    coordinate_frames = []
    
    # --- Head Camera (ä½œä¸ºä¸–ç•Œåæ ‡ç³»åŸç‚¹) ---
    print("  å¤„ç† Head Camera...")
    fx, fy, cx, cy = intrinsics['head']
    pc_head = depth_to_point_cloud(head_depth, head_color, fx, fy, cx, cy, max_depth=MAX_DEPTH_Head)
    print(f"    ç‚¹æ•°: {len(pc_head)}")
    
    clouds_local['head'] = pc_head
    clouds_global.append(pc_head)
    coordinate_frames.append((np.eye(4), "Head_Camera", 0.2))
    
    # --- Left Wrist Camera ---
    print("  å¤„ç† Left Wrist Camera...")
    fx, fy, cx, cy = intrinsics['left']
    pc_left = depth_to_point_cloud(left_depth, left_color, fx, fy, cx, cy, max_depth=MAX_DEPTH_Hand)
    print(f"    ç‚¹æ•°: {len(pc_left)}")
    
    if len(pc_left) > 0:
        # å˜æ¢è·¯å¾„: Cam -> End -> Base -> HeadCam
        # P_Head = T_H_LB @ T_LB_LE @ T_LE_LC @ P_Cam
        T_total_left = T_H_LB @ T_LB_LE @ T_LE_LC
        pc_left_global = transform_point_cloud(pc_left, T_total_left)
        
        clouds_local['left'] = pc_left
        clouds_global.append(pc_left_global)
        coordinate_frames.append((T_total_left, "Left_Camera", 0.15))
        
        print(f"    å˜æ¢åä½ç½®: {T_total_left[:3, 3]}")
    
    # --- Right Wrist Camera ---
    print("  å¤„ç† Right Wrist Camera...")
    fx, fy, cx, cy = intrinsics['right']
    pc_right = depth_to_point_cloud(right_depth, right_color, fx, fy, cx, cy, max_depth=MAX_DEPTH_Hand)
    print(f"    ç‚¹æ•°: {len(pc_right)}")
    
    if len(pc_right) > 0:
        # å˜æ¢è·¯å¾„: Cam -> End -> Base -> HeadCam
        # P_Head = T_H_RB @ T_RB_RE @ T_RE_RC @ P_Cam
        T_total_right = T_H_RB @ T_RB_RE @ T_RE_RC
        pc_right_global = transform_point_cloud(pc_right, T_total_right)
        
        clouds_local['right'] = pc_right
        clouds_global.append(pc_right_global)
        coordinate_frames.append((T_total_right, "Right_Camera", 0.15))
        
        print(f"    å˜æ¢åä½ç½®: {T_total_right[:3, 3]}")
    
    # 5. åæ ‡ç³»è½¬æ¢ (å¯é€‰: è½¬æ¢åˆ°å·¦è‡‚åŸºåº§åæ ‡ç³»)
    print("\n" + "="*80)
    if OUTPUT_FRAME == 'left_base':
        print("ğŸ”„ è½¬æ¢åæ ‡ç³»: Head -> Left Base")
        # T_LB_H æ˜¯ Left Base -> Head çš„å˜æ¢
        # æˆ‘ä»¬éœ€è¦ Head -> Left Base, æ‰€ä»¥å–é€†
        T_LB_H_inv = T_LB_H  # æ³¨æ„: T_LB_H æœ¬èº«å°±æ˜¯ Base->Head, æ‰€ä»¥ inv æ˜¯ Head->Base
        
        clouds_in_left_base = []
        for cloud in clouds_global:
            if len(cloud) > 0:
                cloud_transformed = transform_point_cloud(cloud, T_LB_H_inv)
                clouds_in_left_base.append(cloud_transformed)
        
        clouds_global = clouds_in_left_base
        
        # æ›´æ–°åæ ‡ç³»æ ‡è®°
        coordinate_frames_left_base = []
        for T, label, size in coordinate_frames:
            T_new = T_LB_H_inv @ T
            coordinate_frames_left_base.append((T_new, label, size))
        coordinate_frames = coordinate_frames_left_base
        
        print(f"   âœ… å·²è½¬æ¢åˆ°å·¦è‡‚åŸºåº§åæ ‡ç³»")
    
    # 6. å·¥ä½œç©ºé—´è£å‰ª
    if USE_WORKSPACE_CROP:
        print("\nâœ‚ï¸  å·¥ä½œç©ºé—´è£å‰ª:")
        print(f"   X: [{WORKSPACE_X_RANGE[0]}, {WORKSPACE_X_RANGE[1]}] m")
        print(f"   Y: [{WORKSPACE_Y_RANGE[0]}, {WORKSPACE_Y_RANGE[1]}] m")
        print(f"   Z: [{WORKSPACE_Z_RANGE[0]}, {WORKSPACE_Z_RANGE[1]}] m")
        
        clouds_cropped = []
        for cloud in clouds_global:
            if len(cloud) > 0:
                cloud_cropped = crop_point_cloud(cloud, 
                                                 WORKSPACE_X_RANGE, 
                                                 WORKSPACE_Y_RANGE, 
                                                 WORKSPACE_Z_RANGE)
                if len(cloud_cropped) > 0:
                    clouds_cropped.append(cloud_cropped)
                    print(f"   ä¿ç•™ç‚¹æ•°: {len(cloud)} -> {len(cloud_cropped)}")
        
        clouds_global = clouds_cropped
        print(f"   âœ… è£å‰ªå®Œæˆ")
    
    # 7. æ˜¾ç¤ºåŸå§‹æ‹¼æ¥ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š æ‹¼æ¥ç»Ÿè®¡:")
    total_points = sum(len(c) for c in clouds_global)
    print(f"   æ€»ç‚¹æ•°: {total_points}")
    print(f"   ç›¸æœºæ•°: {len(clouds_global)}")
    print(f"   åæ ‡ç³»: {OUTPUT_FRAME}")
    
    if len(clouds_global) > 0:
        print("\nğŸ‘€ æ˜¾ç¤ºåŸå§‹æ‹¼æ¥ç»“æœ...")
        frame_name = "Left_Base" if OUTPUT_FRAME == 'left_base' else "Head"
        visualize_merged(clouds_global, 
                        title=f"Original Merged (Frame: {frame_name})", 
                        coordinate_frames=coordinate_frames)
    
    # 8. FPS ä¸‹é‡‡æ ·
    print("\n" + "="*80)
    print(f"ğŸ¯ FPS ä¸‹é‡‡æ ·åˆ° {FPS_SAMPLE_POINTS} ç‚¹...")
    
    if len(clouds_global) > 0:
        # åˆå¹¶æ‰€æœ‰ç‚¹äº‘
        merged_cloud = np.vstack(clouds_global)
        print(f"   åˆå¹¶å‰æ€»ç‚¹æ•°: {len(merged_cloud)}")
        
        # è½¬æ¢ä¸º Open3D
        pcd_merged = numpy_to_o3d(merged_cloud)
        
        # å»é™¤ç¦»ç¾¤ç‚¹
        pcd_clean, ind = pcd_merged.remove_statistical_outlier(nb_neighbors=20, std_ratio=2.0)
        print(f"   å»å™ªåç‚¹æ•°: {len(pcd_clean.points)}")
        
        # ä½“ç´ ä¸‹é‡‡æ · (é¢„å¤„ç†)
        voxel_size = 0.005  # 5mm
        pcd_voxel = pcd_clean.voxel_down_sample(voxel_size=voxel_size)
        print(f"   ä½“ç´ ä¸‹é‡‡æ ·({voxel_size}m)å: {len(pcd_voxel.points)}")
        
        # FPS ä¸‹é‡‡æ ·
        if len(pcd_voxel.points) > FPS_SAMPLE_POINTS:
            pcd_fps = pcd_voxel.farthest_point_down_sample(FPS_SAMPLE_POINTS)
            print(f"   FPS é‡‡æ ·å: {len(pcd_fps.points)}")
        else:
            pcd_fps = pcd_voxel
            print(f"   âš ï¸ ç‚¹æ•°ä¸è¶³ {FPS_SAMPLE_POINTS}, ä¿ç•™æ‰€æœ‰ç‚¹: {len(pcd_fps.points)}")
        
        # è½¬æ¢å› numpy
        fps_points = np.asarray(pcd_fps.points)
        fps_colors = np.asarray(pcd_fps.colors)
        fps_cloud = np.hstack((fps_points, fps_colors))
        
        # æ˜¾ç¤º FPS ç»“æœ
        print(f"\nğŸ‘€ æ˜¾ç¤º FPS ä¸‹é‡‡æ ·ç»“æœ ({len(fps_cloud)} ç‚¹)...")
        frame_name = "Left_Base" if OUTPUT_FRAME == 'left_base' else "Head"
        visualize_merged([fps_cloud], 
                        title=f"FPS Sampled ({FPS_SAMPLE_POINTS} points, Frame: {frame_name})", 
                        coordinate_frames=coordinate_frames)
        
        # ä¿å­˜ç»“æœ
        frame_suffix = "leftbase" if OUTPUT_FRAME == 'left_base' else "head"
        output_path = f"pointcloud_frame{FRAME_INDEX}_fps{FPS_SAMPLE_POINTS}_{frame_suffix}.npy"
        np.save(output_path, fps_cloud)
        print(f"\nğŸ’¾ å·²ä¿å­˜ç‚¹äº‘åˆ°: {output_path}")
        print(f"   å½¢çŠ¶: {fps_cloud.shape}")
        print(f"   åæ ‡ç³»: {OUTPUT_FRAME}")
    
    print("\n" + "="*80)
    print("âœ… å®Œæˆ!")

if __name__ == "__main__":
    main()
